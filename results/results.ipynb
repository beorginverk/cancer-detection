{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38464bit91a273bad08b4eae80268dabe9fc5346",
   "display_name": "Python 3.8.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected model is noaug-grad, here are the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pretrainedmodels\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Xception:\n\tMissing key(s) in state_dict: \"last_linear.0.weight\", \"last_linear.0.bias\". \n\tUnexpected key(s) in state_dict: \"last_linear.3.weight\", \"last_linear.3.bias\", \"last_linear.1.weight\", \"last_linear.1.bias\". ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cae141de88cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#load trained model with weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_arch_model.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m    847\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Xception:\n\tMissing key(s) in state_dict: \"last_linear.0.weight\", \"last_linear.0.bias\". \n\tUnexpected key(s) in state_dict: \"last_linear.3.weight\", \"last_linear.3.bias\", \"last_linear.1.weight\", \"last_linear.1.bias\". "
     ]
    }
   ],
   "source": [
    "#load xception model\n",
    "import pretrainedmodels\n",
    "\n",
    "model_name = 'xception' # could be fbresnet152 or inceptionresnetv2\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "#add last layer with 3 classes\n",
    "model.last_linear = nn.Sequential(nn.Linear(2048,3),nn.Softmax())\n",
    "#put model on gpu\n",
    "model.cuda()\n",
    "#load trained model with weights\n",
    "model.load_state_dict(torch.load('torch_updated_trained_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create empty pandas data frame with specified colunm names.\n",
    "results = pd.DataFrame(columns=['Id','task_1','task_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load test images\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "#resize,crop,transfer to pytorch tensor and normalize the images\n",
    "transform = transforms.Compose([transforms.Resize(299),\n",
    "                                     transforms.CenterCrop(299),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                             (0.229, 0.224, 0.225))])                                        \n",
    "test_data = datasets.ImageFolder(root = 'data/test',transform = transform)\n",
    "test_loader = DataLoader(test_data,batch_size = 1,shuffle = False,num_workers = 0)\n",
    "print(test_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Id task_1 task_2\n0                data\\test\\melanoma\\ISIC_0012258.jpg    NaN    NaN\n1                data\\test\\melanoma\\ISIC_0012356.jpg    NaN    NaN\n2                data\\test\\melanoma\\ISIC_0012369.jpg    NaN    NaN\n3                data\\test\\melanoma\\ISIC_0012395.jpg    NaN    NaN\n4                data\\test\\melanoma\\ISIC_0012425.jpg    NaN    NaN\n..                                               ...    ...    ...\n595  data\\test\\seborrheic_keratosis\\ISIC_0014647.jpg    NaN    NaN\n596  data\\test\\seborrheic_keratosis\\ISIC_0014648.jpg    NaN    NaN\n597  data\\test\\seborrheic_keratosis\\ISIC_0014649.jpg    NaN    NaN\n598  data\\test\\seborrheic_keratosis\\ISIC_0014652.jpg    NaN    NaN\n599  data\\test\\seborrheic_keratosis\\ISIC_0014653.jpg    NaN    NaN\n\n[600 rows x 3 columns]\n"
    }
   ],
   "source": [
    "#get all pictures id's\n",
    "import glob\n",
    "test_dir = glob.glob('data/*/*/*')\n",
    "#add to pandas dataframe\n",
    "results['Id'] = test_dir\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define criterion\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test Loss: 0.816364\n\n\nTest Accuracy: 74% (447/600)\n"
    }
   ],
   "source": [
    "#make predictions\n",
    "task_1 = []\n",
    "task_2 = []\n",
    "def test(loaders, model, criterion, use_cuda):\n",
    "    #make list probalities for melanoma (task_1) and seborrheic keratosis (task_2)\n",
    "    \n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders):\n",
    "        with torch.no_grad():\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            #extract melanoma and seborrheic_keratosis_proba probabilities\n",
    "            melanoma_proba = output[0].tolist()[0]\n",
    "            seborrheic_keratosis_proba = output[0].tolist()[1]\n",
    "            \n",
    "            #append melanoma probablilies\n",
    "            task_1.append(melanoma_proba)\n",
    "            #append seborrheic_keratosis probablilies\n",
    "            task_2.append(seborrheic_keratosis_proba)\n",
    "       \n",
    "\n",
    "            \n",
    "\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average test loss \n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "            # convert output probabilities to predicted class\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions to true label\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(test_loader, model, criterion, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Id    task_1    task_2\n0                data\\test\\melanoma\\ISIC_0012258.jpg  0.075565  0.361669\n1                data\\test\\melanoma\\ISIC_0012356.jpg  0.057701  0.449189\n2                data\\test\\melanoma\\ISIC_0012369.jpg  0.267915  0.721688\n3                data\\test\\melanoma\\ISIC_0012395.jpg  0.197210  0.772461\n4                data\\test\\melanoma\\ISIC_0012425.jpg  0.024590  0.371998\n..                                               ...       ...       ...\n595  data\\test\\seborrheic_keratosis\\ISIC_0014647.jpg  0.008840  0.287305\n596  data\\test\\seborrheic_keratosis\\ISIC_0014648.jpg  0.000032  0.000286\n597  data\\test\\seborrheic_keratosis\\ISIC_0014649.jpg  0.000018  0.000214\n598  data\\test\\seborrheic_keratosis\\ISIC_0014652.jpg  0.101073  0.306192\n599  data\\test\\seborrheic_keratosis\\ISIC_0014653.jpg  0.000079  0.000211\n\n[600 rows x 3 columns]\n"
    }
   ],
   "source": [
    "#add those lists as entries to our task_1 and task_2 columns\n",
    "\n",
    "results['task_1'] = task_1\n",
    "results['task_2'] = task_2\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the pandas data frame to a csv\n",
    "results.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The model performed extremely well in categorizing bening lesions as benign, but extremely poor at classifying melanoma correctly. This is extremely concerning as the algorithm could be missing patients who have cancer.\n",
    "I will attempt to improve the model by implementing more data with positive melanoma.\n",
    "\n",
    "\n",
    "<img src=\"results/first_try.png\" alt=\"first_try\" width=\"500\"/>                <img src=\"results/first_try_confusion_matrix.py.png\" alt=\"first_try_confusion_matrix\" width=\"500\"/>                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}